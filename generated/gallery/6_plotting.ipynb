{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Plotting functions\n\nIn this tutorial, we will demonstrate how to plot\naudio data and spectrograms using the built-in\nplotting functions in `soundevent`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Audio Arrays\n\nFirst lets compute the spectrogram of an audio file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from soundevent import arrays, audio, data\n\nrecording = data.Recording.from_file(\"sample_audio.wav\")\nwave = audio.load_recording(recording)\nspectrogram = arrays.to_db(\n    audio.compute_spectrogram(\n        wave,\n        window_size=0.064,\n        hop_size=0.032,\n    )\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both the wave and spectrogram are [xarray.DataArray][xarray.DataArray]\nobjects. Hence we can use the built-in plotting functions to visualize them.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "wave.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And the spectrogram.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "spectrogram.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "!!! note\n\n    xarray plotting functions are quite flexible and allow you to customize\n    the plot. To see how to use the xarray plotting functions, see the\n    [xarray plotting documentation](https://docs.xarray.dev/en/latest/user-guide/plotting.html).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Geometries\n\nTo plot geometries, we can use the `plot_geometry` function in the\n`soundevent.plot` module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from soundevent import plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can plot the different geometries that are defined within `soundevent`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "time_stamp = data.TimeStamp(coordinates=0.1)\ntime_interval = data.TimeInterval(coordinates=[0.2, 0.3])\npoint = data.Point(coordinates=[0.4, 6000])\nbox = data.BoundingBox(coordinates=[0.5, 3000, 0.6, 5000])\nline = data.LineString(coordinates=[[0.7, 2000], [0.8, 3000], [0.9, 8000]])\npolygon = data.Polygon(\n    coordinates=[\n        [\n            [1.0, 4000],\n            [1.1, 5000],\n            [1.2, 4000],\n            [1.1, 3000],\n            [1.0, 4000],\n        ]\n    ]\n)\n\nax = plot.plot_geometry(time_stamp)\nplot.plot_geometry(time_interval, ax=ax, color=\"red\")\nplot.plot_geometry(point, ax=ax, color=\"green\")\nplot.plot_geometry(box, ax=ax, color=\"blue\")\nplot.plot_geometry(line, ax=ax, color=\"purple\", linestyle=\"--\")\nplot.plot_geometry(polygon, ax=ax, color=\"orange\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sound Event Annotations\n\nTo plot sound event annotations, we can use the `plot_annotation` function in\nthe `soundevent.plot` module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sound_event_annotations = [\n    data.SoundEventAnnotation(\n        tags=[\n            data.Tag(key=\"animal\", value=\"dog\"),\n            data.Tag(key=\"loudness\", value=\"loud\"),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[0.58, 100, 0.78, 2000]),\n        ),\n    ),\n    data.SoundEventAnnotation(\n        tags=[\n            data.Tag(key=\"animal\", value=\"dog\"),\n            data.Tag(key=\"loudness\", value=\"loud\"),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.08, 60, 1.34, 1600]),\n        ),\n    ),\n    data.SoundEventAnnotation(\n        tags=[\n            data.Tag(key=\"animal\", value=\"dog\"),\n            data.Tag(key=\"loudness\", value=\"medium\"),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.52, 30, 1.69, 1400]),\n        ),\n    ),\n    data.SoundEventAnnotation(\n        tags=[\n            data.Tag(key=\"animal\", value=\"dog\"),\n            data.Tag(key=\"loudness\", value=\"soft\"),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.98, 30, 2.1, 800]),\n        ),\n    ),\n    data.SoundEventAnnotation(\n        tags=[\n            data.Tag(key=\"animal\", value=\"dog\"),\n            data.Tag(key=\"loudness\", value=\"soft\"),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[2.45, 30, 2.70, 1300]),\n        ),\n    ),\n]\n\nax = plot.create_axes()\nspectrogram.plot(ax=ax, cmap=\"gray\")\n\nplot.plot_annotations(\n    sound_event_annotations,\n    ax=ax,\n    color=\"red\",\n    add_points=False,\n    time_offset=0.03,\n    freq_offset=300,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sound Event Predictions\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sound_event_predictions = [\n    data.SoundEventPrediction(\n        score=0.9,\n        tags=[\n            data.PredictedTag(\n                score=0.95, tag=data.Tag(key=\"animal\", value=\"dog\")\n            ),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[0.58, 100, 0.78, 2000]),\n        ),\n    ),\n    data.SoundEventPrediction(\n        score=0.8,\n        tags=[\n            data.PredictedTag(\n                score=0.9, tag=data.Tag(key=\"animal\", value=\"dog\")\n            ),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.08, 60, 1.34, 1600]),\n        ),\n    ),\n    data.SoundEventPrediction(\n        score=0.4,\n        tags=[\n            data.PredictedTag(\n                score=0.7, tag=data.Tag(key=\"animal\", value=\"dog\")\n            ),\n            data.PredictedTag(\n                score=0.3, tag=data.Tag(key=\"animal\", value=\"cat\")\n            ),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.52, 30, 1.69, 1400]),\n        ),\n    ),\n    data.SoundEventPrediction(\n        score=0.3,\n        tags=[\n            data.PredictedTag(\n                score=0.5, tag=data.Tag(key=\"animal\", value=\"dog\")\n            ),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[1.98, 30, 2.1, 800]),\n        ),\n    ),\n    data.SoundEventPrediction(\n        score=0.8,\n        tags=[\n            data.PredictedTag(\n                score=0.4, tag=data.Tag(key=\"animal\", value=\"dog\")\n            ),\n        ],\n        sound_event=data.SoundEvent(\n            recording=recording,\n            geometry=data.BoundingBox(coordinates=[2.45, 30, 2.70, 1300]),\n        ),\n    ),\n]\n\nax = plot.create_axes()\nspectrogram.plot(ax=ax, cmap=\"gray\")\nplot.plot_predictions(\n    sound_event_predictions,\n    ax=ax,\n    color=\"red\",\n    add_points=False,\n    time_offset=0.03,\n    freq_offset=300,\n)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}